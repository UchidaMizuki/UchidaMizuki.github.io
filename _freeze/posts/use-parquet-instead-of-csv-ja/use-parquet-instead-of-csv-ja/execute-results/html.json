{
  "hash": "c2723de0f7dbd3778675c98657f9b140",
  "result": {
    "markdown": "---\ntitle: \"🗾CSVの代わりにParquetを使ってみよう！\"\nlang: ja\ndate: \"2022-06-07\"\ncategories: [parquet, arrow, R, Japanese]\nfig-align: center\nimage: https://www.apache.org/logos/res/parquet/parquet.png\ndraft: true\n---\n\n\nデータフレーム（Data Frames）は，データ分析において最も基本的なデータ構造の1つです．\n\nRの[tibble](https://tibble.tidyverse.org)・[dplyr](https://dplyr.tidyverse.org)やPythonの[pandas](https://pandas.pydata.org)などのデータフレーム操作のためのパッケージを使えば，これまでExcelなどの表計算ソフトで行っていたデータ分析をさらに効率的に行うことができます．\n\nこのようにデータ分析のためのツールが充実する一方で，データフレームの保存にはExcelなどとの互換性が高いCSVが未だに広く使われています．\n\nCSVは，テキストデータであるため，様々なソフトと互換性があるなどの利点がありますが，必ずしもデータ分析に適したファイル形式とは言えません．\n\nCSVの代替として有望なファイル形式に，Parquetと呼ばれるものがあります．\n\n以下では，CSVとParquetを比較し，Parquetのメリットを紹介します．\n\n## サンプルデータ（tidy dataについて）\n\nここでは，Rのarrowパッケージを用いてParquetの保存を行ってみます．\n\nサンプルデータとして，tidyrパッケージで提供されている`who` （[世界保健機関（WHO）結核データ](https://www.who.int/teams/global-tuberculosis-programme/data)）を用います．\n\nデータ分析では，近年，整然データ（[tidy data](https://ja.wikipedia.org/wiki/Tidy_data)）の概念が普及してきています．tidy dataは，個々の変数が1つの列をなし，個々の観測（値）が1つの行をなすようなデータです．\n\n`who`は，tidy dataと言えるでしょうか？`who`には，`\"new_sp_m014\"` ～`\"newrel_f65\"` の列が存在しますが，これらの列名には，列ごとに，診断結果（`sp`や`sel`）・性別（`m`と`f`）・年齢階級（`014`や`65`）といった複数の変数が含まれています．そのため，`who` は，tidy dataでないといえます．そこで，[こちら](https://tidyr.tidyverse.org/articles/pivot.html)に従ってtidy dataである`who_longer`に変形します．\n\nデータ分析では，`who` より`who_longer` のほうを分析が行いやすい一方で，行数は`who`（約7,000行）より`who_longer` （約400,000行）のほうが約50倍多いことがわかります．そのため，`who_longer`のようなデータを，テキストファイルであるCSVで保存すると容量が増大してしまいます．\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(fs)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlevels_gender <- c(\"f\", \"m\")\nlevels_age <- c(\"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\")\n\nwho_longer <- who |> \n  pivot_longer(cols = new_sp_m014:newrel_f65,\n               names_to = c(\"diagnosis\", \"gender\", \"age\"), \n               names_pattern = \"new_?(.*)_(.)(.*)\",\n               names_transform = list(gender = ~ .x |> \n                                        readr::parse_factor(levels = levels_gender),\n                                      age = ~ .x |> \n                                        readr::parse_factor(levels = levels_age,\n                                                            ordered = TRUE)),\n               values_to = \"count\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# データ整形前\nprint(who, n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,240 × 60\n  country   iso2  iso3   year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544\n  <chr>     <chr> <chr> <int>       <int>        <int>        <int>        <int>\n1 Afghanis… AF    AFG    1980          NA           NA           NA           NA\n2 Afghanis… AF    AFG    1981          NA           NA           NA           NA\n3 Afghanis… AF    AFG    1982          NA           NA           NA           NA\n4 Afghanis… AF    AFG    1983          NA           NA           NA           NA\n5 Afghanis… AF    AFG    1984          NA           NA           NA           NA\n# … with 7,235 more rows, and 52 more variables: new_sp_m4554 <int>,\n#   new_sp_m5564 <int>, new_sp_m65 <int>, new_sp_f014 <int>,\n#   new_sp_f1524 <int>, new_sp_f2534 <int>, new_sp_f3544 <int>,\n#   new_sp_f4554 <int>, new_sp_f5564 <int>, new_sp_f65 <int>,\n#   new_sn_m014 <int>, new_sn_m1524 <int>, new_sn_m2534 <int>,\n#   new_sn_m3544 <int>, new_sn_m4554 <int>, new_sn_m5564 <int>,\n#   new_sn_m65 <int>, new_sn_f014 <int>, new_sn_f1524 <int>, …\n```\n:::\n\n```{.r .cell-code}\n# データ整形後\nprint(who_longer, n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 405,440 × 8\n  country     iso2  iso3   year diagnosis gender age   count\n  <chr>       <chr> <chr> <int> <chr>     <fct>  <ord> <int>\n1 Afghanistan AF    AFG    1980 sp        m      014      NA\n2 Afghanistan AF    AFG    1980 sp        m      1524     NA\n3 Afghanistan AF    AFG    1980 sp        m      2534     NA\n4 Afghanistan AF    AFG    1980 sp        m      3544     NA\n5 Afghanistan AF    AFG    1980 sp        m      4554     NA\n# … with 405,435 more rows\n```\n:::\n:::\n\n\n## Parquetの保存方法\n\n`write_csv()` でCSVを保存できるとの同様に`write_parquet()` で簡単に，Parquetを保存することができます．`who_longer`を保存してみましょう．\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# CSVを保存\nwrite_csv(who_longer, \"who_longer.csv\")\n\n# Parquetを保存\nwrite_parquet(who_longer, \"who_longer.parquet\")\n```\n:::\n\n\n## Parquetのメリット\n\n### メリット1: CSVと比べてファイル容量が軽い\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# CSV\nfile_size(\"who_longer.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n14.1M\n```\n:::\n\n```{.r .cell-code}\n# Parquet\nfile_size(\"who_longer.parquet\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n154K\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# file_size_csv <- file_size(\"who_longer.csv\")\n# file_size_parquet <- file_size(\"who_longer.parquet\")\n# \n# file_size_csv / file_size_parquet\n# \n# dir_create(\"who_longer\")\n# who_longer_splitted <- who_longer |> \n#   group_by(age) |> \n#   group_walk(~ .x |> \n#                write_parquet(str_glue(\"who_longer/who_longer_{.y$age}.parquet\")),\n#   .keep = TRUE)\n# \n# read_parquet(\"who_longer.parquet\")\n# \n# open_dataset(\"who_longer\") |> \n#   collect()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# import pandas as pd\n# \n# pd.read_parquet('who_longer.parquet')\n```\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}